{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Created on 24-April-2020 -- By Naganandini Subbaraja#####\n",
    "\n",
    "### Analysis of Role of Activation Functions (Tanh, ReLU) and Pooling Techniques\n",
    "\n",
    "This is a naive attempt to understand the impact of Activation Functions, Pooling Techniques, number of Epochs in LeNet-5. \n",
    "\n",
    "4 different combinations has been used. Namely:\n",
    "1. Tanh Activation function with Average Pooling\n",
    "2. Tanh Activation function with Max Pooling\n",
    "3. ReLU Activation function with Average Pooling\n",
    "4. ReLU Activation function with Max Pooling\n",
    "\n",
    "**NOTE1:** LeNet-5, from the paper Gradient-Based Learning Applied to Document Recognition, is a very efficient convolutional neural network for handwritten character recognition. You may find the paper here:\n",
    "<a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf\" target=\"_blank\">Paper: <u>Gradient-Based Learning Applied to Document Recognition</u></a>\n",
    "**Authors**: Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner\n",
    "**Published in**: Proceedings of the IEEE (1998)\n",
    "\n",
    "**NOTE2:** The dataset taken here is very small in the context of Deep Learning. \n",
    "My intention was NOT to use any standard pre-processed data so that I can comprehend the concepts a little better :)\n",
    "\n",
    "I have a folder named **dataset_train.** In this I have three different folders (named as gaanu, chubby, dyutith -- Names of children) maintained for 3 different classes which has around 10 images(of children) in each of these folders.\n",
    "\n",
    "One can surely try with various other datasets, tweak the code a little here and there.... and share the results!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "print(tensorflow.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the path of the dataset\n",
    "path = 'C:/Users/Naganandini/Nandu/DEEP learning/Advanced CNN/LeNet/dataset_train'\n",
    "data_dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the images of dataset-chubby\n",
      "\n",
      "Loading the images of dataset-dyutith\n",
      "\n",
      "Loading the images of dataset-gaanu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 3\n",
    "labels_name={'gaanu':0,'chubby':1,'dyutith':2}\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "#Load the dataset from the directories\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(path+'/'+ dataset)\n",
    "\tprint ('Loading the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tlabel = labels_name[dataset]\n",
    "\tfor img in img_list:\n",
    "\t\tinput_img=cv2.imread(path + '/'+ dataset + '/'+ img )\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(128,128))\n",
    "\t\timg_data_list.append(input_img_resize)\n",
    "\t\tlabels_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_data.shape\n",
      "(36, 128, 128, 3)\n",
      "Labels:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "The count of number of samples for different classes:\n",
      "(array([0, 1, 2]), array([13, 13, 10], dtype=int64))\n",
      "After one-hot encoding: [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Change the image data and labels data to ndarray\n",
    "img_data = np.array(img_data_list)\n",
    "print('img_data.shape')\n",
    "print(img_data.shape)\n",
    "labels = np.array(labels_list)\n",
    "print(\"Labels:\")\n",
    "print(labels)\n",
    "print(\"The count of number of samples for different classes:\")\n",
    "print(np.unique(labels,return_counts=True))\n",
    "# convert class labels to one-hot encoding\n",
    "Y = keras.utils.to_categorical(labels, 3)\n",
    "print('After one-hot encoding:', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "# Peforming reshaping operation\n",
    "x_train = x_train.reshape(x_train.shape[0], 128, 128, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 128, 128, 3)\n",
    "# Normalization\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the input shape for the model\n",
    "input_shape=img_data[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 27ms/step - loss: 1.1332 - accuracy: 0.3571 - val_loss: 4.8241 - val_accuracy: 0.2500\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.1933 - accuracy: 0.3929 - val_loss: 3.6980 - val_accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.3133 - accuracy: 0.3929 - val_loss: 2.7148 - val_accuracy: 0.2500\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.5851 - accuracy: 0.3929 - val_loss: 2.1734 - val_accuracy: 0.2500\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2701 - accuracy: 0.4286 - val_loss: 1.9708 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2226 - accuracy: 0.3214 - val_loss: 1.7777 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.9734 - accuracy: 0.3214 - val_loss: 1.5582 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.6287 - accuracy: 0.4643 - val_loss: 1.1388 - val_accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.1093 - accuracy: 0.4286 - val_loss: 2.4161 - val_accuracy: 0.2500\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.4256 - accuracy: 0.2857 - val_loss: 1.2559 - val_accuracy: 0.2500\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0176 - accuracy: 0.4643 - val_loss: 1.2654 - val_accuracy: 0.2500\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.0511 - accuracy: 0.4286 - val_loss: 1.1524 - val_accuracy: 0.2500\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.0064 - accuracy: 0.4643 - val_loss: 1.0513 - val_accuracy: 0.3750\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9736 - accuracy: 0.6786 - val_loss: 0.9984 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9684 - accuracy: 0.5357 - val_loss: 0.9831 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.9482 - accuracy: 0.5000 - val_loss: 0.9944 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.9131 - accuracy: 0.7143 - val_loss: 1.0240 - val_accuracy: 0.3750\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.8777 - accuracy: 0.7500 - val_loss: 1.0331 - val_accuracy: 0.3750\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.8390 - accuracy: 0.7857 - val_loss: 0.9820 - val_accuracy: 0.3750\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.7951 - accuracy: 0.7857 - val_loss: 0.9094 - val_accuracy: 0.6250\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.7673 - accuracy: 0.8214 - val_loss: 0.9173 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.7268 - accuracy: 0.8571 - val_loss: 0.9737 - val_accuracy: 0.3750\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7030 - accuracy: 0.8214 - val_loss: 0.9544 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.6716 - accuracy: 0.8929 - val_loss: 0.8902 - val_accuracy: 0.6250\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.6382 - accuracy: 1.0000 - val_loss: 0.8849 - val_accuracy: 0.6250\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.6066 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.6250\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5761 - accuracy: 0.9643 - val_loss: 0.9276 - val_accuracy: 0.6250\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.5434 - accuracy: 0.9643 - val_loss: 0.8692 - val_accuracy: 0.6250\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.5045 - accuracy: 0.9643 - val_loss: 0.8507 - val_accuracy: 0.6250\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.4706 - accuracy: 0.9643 - val_loss: 0.8754 - val_accuracy: 0.6250\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.4426 - accuracy: 0.9643 - val_loss: 0.8642 - val_accuracy: 0.6250\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.4178 - accuracy: 0.9643 - val_loss: 0.8173 - val_accuracy: 0.6250\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.9643 - val_loss: 0.8105 - val_accuracy: 0.6250\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.8554 - val_accuracy: 0.6250\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.3407 - accuracy: 0.9643 - val_loss: 0.8766 - val_accuracy: 0.6250\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.3190 - accuracy: 0.9643 - val_loss: 0.8292 - val_accuracy: 0.6250\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.2924 - accuracy: 0.9643 - val_loss: 0.7785 - val_accuracy: 0.6250\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 0.7748 - val_accuracy: 0.6250\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 0.8041 - val_accuracy: 0.6250\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.2361 - accuracy: 1.0000 - val_loss: 0.8246 - val_accuracy: 0.6250\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.2202 - accuracy: 1.0000 - val_loss: 0.8162 - val_accuracy: 0.6250\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.2029 - accuracy: 1.0000 - val_loss: 0.8050 - val_accuracy: 0.6250\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.8131 - val_accuracy: 0.6250\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.1767 - accuracy: 1.0000 - val_loss: 0.8381 - val_accuracy: 0.6250\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.8564 - val_accuracy: 0.6250\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.6250\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.1447 - accuracy: 1.0000 - val_loss: 0.8499 - val_accuracy: 0.6250\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.1341 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.6250\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.8488 - val_accuracy: 0.6250\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.1166 - accuracy: 1.0000 - val_loss: 0.8560 - val_accuracy: 0.6250\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.6250\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.8584 - val_accuracy: 0.6250\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0974 - accuracy: 1.0000 - val_loss: 0.8519 - val_accuracy: 0.6250\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0918 - accuracy: 1.0000 - val_loss: 0.8472 - val_accuracy: 0.6250\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.8486 - val_accuracy: 0.6250\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.8570 - val_accuracy: 0.6250\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.6250\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.8818 - val_accuracy: 0.6250\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.6250\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.8973 - val_accuracy: 0.6250\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.6250\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.6250\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.9027 - val_accuracy: 0.6250\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.6250\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.9079 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.9132 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.9203 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.9286 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.9464 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.7500\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.9812 - val_accuracy: 0.6250\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.6250\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 0.6250\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.6250\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.0206 - val_accuracy: 0.6250\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.0303 - val_accuracy: 0.6250\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.0389 - val_accuracy: 0.6250\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.0463 - val_accuracy: 0.6250\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.6250\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.0566 - val_accuracy: 0.6250\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.6250\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.0616 - val_accuracy: 0.6250\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.6250\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.0630 - val_accuracy: 0.6250\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.6250\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.0627 - val_accuracy: 0.6250\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.0625 - val_accuracy: 0.6250\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.0623 - val_accuracy: 0.6250\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.0625 - val_accuracy: 0.6250\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.6250\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 0.6250\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.6250\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.6250\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.6250\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 1.0726 - val_accuracy: 0.6250\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.0762 - val_accuracy: 0.6250\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.6250\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.6250\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.0894 - val_accuracy: 0.6250\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.0943 - val_accuracy: 0.6250\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 0.6250\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.1043 - val_accuracy: 0.6250\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.6250\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.1138 - val_accuracy: 0.6250\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.6250\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.1224 - val_accuracy: 0.6250\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1263 - val_accuracy: 0.6250\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.6250\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.1334 - val_accuracy: 0.6250\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.1365 - val_accuracy: 0.6250\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1394 - val_accuracy: 0.6250\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1420 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.1444 - val_accuracy: 0.6250\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1466 - val_accuracy: 0.6250\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.1486 - val_accuracy: 0.6250\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1504 - val_accuracy: 0.6250\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.1520 - val_accuracy: 0.6250\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.1534 - val_accuracy: 0.6250\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.1547 - val_accuracy: 0.6250\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.1559 - val_accuracy: 0.6250\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.1570 - val_accuracy: 0.6250\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.1581 - val_accuracy: 0.6250\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.1591 - val_accuracy: 0.6250\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 1.1602 - val_accuracy: 0.6250\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.1613 - val_accuracy: 0.6250\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1625 - val_accuracy: 0.6250\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.1638 - val_accuracy: 0.6250\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.1652 - val_accuracy: 0.6250\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.1666 - val_accuracy: 0.6250\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1681 - val_accuracy: 0.6250\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.1697 - val_accuracy: 0.6250\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1714 - val_accuracy: 0.6250\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.1731 - val_accuracy: 0.6250\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.6250\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.6250\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.1784 - val_accuracy: 0.6250\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1802 - val_accuracy: 0.6250\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.1819 - val_accuracy: 0.6250\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1837 - val_accuracy: 0.6250\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.6250\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.1870 - val_accuracy: 0.6250\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1887 - val_accuracy: 0.6250\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.1903 - val_accuracy: 0.6250\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.1919 - val_accuracy: 0.6250\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.1935 - val_accuracy: 0.6250\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.1951 - val_accuracy: 0.6250\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.1967 - val_accuracy: 0.6250\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.1982 - val_accuracy: 0.6250\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.1998 - val_accuracy: 0.6250\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.2014 - val_accuracy: 0.6250\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.2029 - val_accuracy: 0.6250\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2045 - val_accuracy: 0.6250\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.2060 - val_accuracy: 0.6250\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.2076 - val_accuracy: 0.6250\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2091 - val_accuracy: 0.6250\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.6250\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2122 - val_accuracy: 0.6250\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.2137 - val_accuracy: 0.6250\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.2152 - val_accuracy: 0.6250\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2168 - val_accuracy: 0.6250\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.6250\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2198 - val_accuracy: 0.6250\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2213 - val_accuracy: 0.6250\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2228 - val_accuracy: 0.6250\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2243 - val_accuracy: 0.6250\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2258 - val_accuracy: 0.6250\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2273 - val_accuracy: 0.6250\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.2288 - val_accuracy: 0.6250\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2317 - val_accuracy: 0.6250\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2332 - val_accuracy: 0.6250\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2346 - val_accuracy: 0.6250\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2360 - val_accuracy: 0.6250\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2375 - val_accuracy: 0.6250\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2389 - val_accuracy: 0.6250\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2403 - val_accuracy: 0.6250\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2416 - val_accuracy: 0.6250\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2430 - val_accuracy: 0.6250\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2443 - val_accuracy: 0.6250\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.6250\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2470 - val_accuracy: 0.6250\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2483 - val_accuracy: 0.6250\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2496 - val_accuracy: 0.6250\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2509 - val_accuracy: 0.6250\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2522 - val_accuracy: 0.6250\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2535 - val_accuracy: 0.6250\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2548 - val_accuracy: 0.6250\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.2560 - val_accuracy: 0.6250\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2573 - val_accuracy: 0.6250\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.2586 - val_accuracy: 0.6250\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2598 - val_accuracy: 0.6250\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2611 - val_accuracy: 0.6250\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2623 - val_accuracy: 0.6250\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2636 - val_accuracy: 0.6250\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2648 - val_accuracy: 0.6250\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.6250\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2672 - val_accuracy: 0.6250\n",
      "8/8 [==============================] - 0s 6ms/step\n",
      "Test Loss: 1.2672468423843384\n",
      "Test accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "#Building the model:\n",
    "# This is the basic LeNET model with ACTIVATION function as TANH and AveragePooling2D\n",
    "# Step 1 - Convolution\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=input_shape))\n",
    "# Step 2 - Pooling\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "# Step 3 - Adding a second convolutional layer with pooling \n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n",
    "model.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "# Step 4 - Flattening\n",
    "model.add(Flatten())\n",
    "# Step 5 - Full connection\n",
    "model.add(Dense(120, activation='tanh'))\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "# Step 6 - Final Layer for classification\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Defining Metrics for measuring the model behaviour\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Training\n",
    "num_epoch=200\n",
    "hist = model.fit(x_train, y_train, batch_size=32, epochs= num_epoch, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 1.0899 - accuracy: 0.4286 - val_loss: 6.3924 - val_accuracy: 0.2500\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.9547 - accuracy: 0.3929 - val_loss: 4.8185 - val_accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.4250 - accuracy: 0.3929 - val_loss: 3.0275 - val_accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.9527 - accuracy: 0.6429 - val_loss: 2.3171 - val_accuracy: 0.2500\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.5995 - accuracy: 0.2857 - val_loss: 1.3650 - val_accuracy: 0.3750\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9152 - accuracy: 0.5714 - val_loss: 0.8723 - val_accuracy: 0.6250\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.6146 - accuracy: 0.8571 - val_loss: 0.9280 - val_accuracy: 0.7500\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.7930 - accuracy: 0.6071 - val_loss: 0.8185 - val_accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.4478 - accuracy: 0.8214 - val_loss: 0.8297 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.2907 - accuracy: 0.8929 - val_loss: 0.9586 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.8929 - val_loss: 0.7338 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.1762 - accuracy: 0.9643 - val_loss: 0.5602 - val_accuracy: 0.7500\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.7500\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.7500\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.7500\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 0.7500\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.6250\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.7035 - val_accuracy: 0.6250\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.7733 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.8308 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.7398 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.6751 - val_accuracy: 0.6250\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8750\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.6764 - val_accuracy: 0.8750\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8750\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.8750\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6119 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6022 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.8750\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.8750\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.6465 - val_accuracy: 0.8750\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.6513 - val_accuracy: 0.8750\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.6546 - val_accuracy: 0.8750\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8750\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6577 - val_accuracy: 0.8750\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.8750\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.6586 - val_accuracy: 0.8750\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.6595 - val_accuracy: 0.8750\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8750\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8750\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 0.8750\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6710 - val_accuracy: 0.8750\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6757 - val_accuracy: 0.8750\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 0.8750\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.8750\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8750\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8750\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.8750\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.8750\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6977 - val_accuracy: 0.8750\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6975 - val_accuracy: 0.8750\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6967 - val_accuracy: 0.8750\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6954 - val_accuracy: 0.8750\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8750\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8750\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8750\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6907 - val_accuracy: 0.8750\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8750\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8750\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8750\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6911 - val_accuracy: 0.8750\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.8750\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.8750\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.8750\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6936 - val_accuracy: 0.8750\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6938 - val_accuracy: 0.8750\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8750\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.8750\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6929 - val_accuracy: 0.8750\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6921 - val_accuracy: 0.8750\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6913 - val_accuracy: 0.8750\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6904 - val_accuracy: 0.8750\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.8750\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8750\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8750\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8750\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6880 - val_accuracy: 0.8750\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.8750\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6884 - val_accuracy: 0.8750\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6889 - val_accuracy: 0.8750\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6895 - val_accuracy: 0.8750\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6901 - val_accuracy: 0.8750\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.8750\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6915 - val_accuracy: 0.8750\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.8750\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6927 - val_accuracy: 0.8750\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.8750\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8750\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.8750\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6943 - val_accuracy: 0.8750\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.8750\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6952 - val_accuracy: 0.8750\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6955 - val_accuracy: 0.7500\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6959 - val_accuracy: 0.7500\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.7500\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.7500\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6976 - val_accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6982 - val_accuracy: 0.7500\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6989 - val_accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.7500\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7004 - val_accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7012 - val_accuracy: 0.7500\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.7500\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7027 - val_accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7033 - val_accuracy: 0.7500\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.7500\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7052 - val_accuracy: 0.7500\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.7500\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7062 - val_accuracy: 0.7500\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7071 - val_accuracy: 0.7500\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 9.9440e-04 - accuracy: 1.0000 - val_loss: 0.7076 - val_accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 9.8746e-04 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 9.8060e-04 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.7383e-04 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.6713e-04 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 9.6050e-04 - accuracy: 1.0000 - val_loss: 0.7101 - val_accuracy: 0.7500\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.5400e-04 - accuracy: 1.0000 - val_loss: 0.7107 - val_accuracy: 0.7500\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.4754e-04 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.7500\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.4118e-04 - accuracy: 1.0000 - val_loss: 0.7118 - val_accuracy: 0.7500\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.3488e-04 - accuracy: 1.0000 - val_loss: 0.7123 - val_accuracy: 0.7500\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.2866e-04 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.7500\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.2253e-04 - accuracy: 1.0000 - val_loss: 0.7134 - val_accuracy: 0.7500\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.1645e-04 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.1047e-04 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.7500\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.0454e-04 - accuracy: 1.0000 - val_loss: 0.7150 - val_accuracy: 0.7500\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.9868e-04 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.7500\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.9288e-04 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.8717e-04 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.8150e-04 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.7591e-04 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.7036e-04 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.6490e-04 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 8.5950e-04 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.5415e-04 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.4887e-04 - accuracy: 1.0000 - val_loss: 0.7194 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.4364e-04 - accuracy: 1.0000 - val_loss: 0.7198 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.3847e-04 - accuracy: 1.0000 - val_loss: 0.7202 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.3336e-04 - accuracy: 1.0000 - val_loss: 0.7207 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.2830e-04 - accuracy: 1.0000 - val_loss: 0.7211 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.2329e-04 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.1836e-04 - accuracy: 1.0000 - val_loss: 0.7220 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.1346e-04 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.0859e-04 - accuracy: 1.0000 - val_loss: 0.7229 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.0380e-04 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.9906e-04 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.9437e-04 - accuracy: 1.0000 - val_loss: 0.7242 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 7.8973e-04 - accuracy: 1.0000 - val_loss: 0.7246 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 7.8511e-04 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 7.8057e-04 - accuracy: 1.0000 - val_loss: 0.7254 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 7.7607e-04 - accuracy: 1.0000 - val_loss: 0.7258 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 7.7162e-04 - accuracy: 1.0000 - val_loss: 0.7262 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.6720e-04 - accuracy: 1.0000 - val_loss: 0.7266 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.6285e-04 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.5849e-04 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.5422e-04 - accuracy: 1.0000 - val_loss: 0.7278 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.5000e-04 - accuracy: 1.0000 - val_loss: 0.7282 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.4581e-04 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.4166e-04 - accuracy: 1.0000 - val_loss: 0.7290 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.3754e-04 - accuracy: 1.0000 - val_loss: 0.7294 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.3345e-04 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.2943e-04 - accuracy: 1.0000 - val_loss: 0.7302 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.2543e-04 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.2149e-04 - accuracy: 1.0000 - val_loss: 0.7309 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.1758e-04 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.1370e-04 - accuracy: 1.0000 - val_loss: 0.7317 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 7.0985e-04 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.0605e-04 - accuracy: 1.0000 - val_loss: 0.7325 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.0230e-04 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.9856e-04 - accuracy: 1.0000 - val_loss: 0.7332 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.9484e-04 - accuracy: 1.0000 - val_loss: 0.7336 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.9118e-04 - accuracy: 1.0000 - val_loss: 0.7340 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.8756e-04 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.8396e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.8040e-04 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.7500\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Test Loss: 0.7350984811782837\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "#Building the model:\n",
    "# This is the basic LeNET model with ACTIVATION function as TANH and POOLING as MAXPOOLING2D\n",
    "model1 = Sequential()\n",
    "model1.add(Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=input_shape))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(16, kernel_size=(5, 5), activation='tanh'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(120, activation='tanh'))\n",
    "model1.add(Dense(84, activation='tanh'))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "model1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Training\n",
    "num_epoch=200\n",
    "hist1 = model1.fit(x_train, y_train, batch_size=32, epochs= num_epoch, verbose=1, validation_data=(x_test, y_test))\n",
    "score1 = model1.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score1[0])\n",
    "print('Test accuracy:', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 1.0995 - accuracy: 0.2857 - val_loss: 2.5314 - val_accuracy: 0.2500\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.7598 - accuracy: 0.3929 - val_loss: 1.1381 - val_accuracy: 0.6250\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2648 - accuracy: 0.5000 - val_loss: 0.9913 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.0980 - accuracy: 0.3571 - val_loss: 1.0369 - val_accuracy: 0.3750\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.9405 - accuracy: 0.4643 - val_loss: 1.1831 - val_accuracy: 0.2500\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.9372 - accuracy: 0.3929 - val_loss: 1.1290 - val_accuracy: 0.2500\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.8679 - accuracy: 0.4643 - val_loss: 0.9692 - val_accuracy: 0.3750\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.7732 - accuracy: 0.8214 - val_loss: 0.8556 - val_accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.7394 - accuracy: 0.8571 - val_loss: 0.8124 - val_accuracy: 0.6250\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.6624 - accuracy: 0.8571 - val_loss: 0.7953 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.8571 - val_loss: 0.7969 - val_accuracy: 0.6250\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.5330 - accuracy: 0.8214 - val_loss: 0.7560 - val_accuracy: 0.6250\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.4698 - accuracy: 0.8571 - val_loss: 0.6796 - val_accuracy: 0.7500\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.3995 - accuracy: 0.8929 - val_loss: 0.6159 - val_accuracy: 0.7500\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 0.3485 - accuracy: 0.8929 - val_loss: 0.5825 - val_accuracy: 0.6250\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.2905 - accuracy: 0.9286 - val_loss: 0.5884 - val_accuracy: 0.7500\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.2363 - accuracy: 0.9643 - val_loss: 0.6239 - val_accuracy: 0.7500\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 0.1982 - accuracy: 0.9643 - val_loss: 0.6541 - val_accuracy: 0.6250\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 0.1582 - accuracy: 0.9643 - val_loss: 0.6433 - val_accuracy: 0.6250\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.1287 - accuracy: 1.0000 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.6250\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.5561 - val_accuracy: 0.6250\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.6250\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.5962 - val_accuracy: 0.6250\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 0.7500\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.7500\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.7500\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6759 - val_accuracy: 0.7500\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.7221e-04 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9687e-04 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.4614e-04 - accuracy: 1.0000 - val_loss: 0.8654 - val_accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.0568e-04 - accuracy: 1.0000 - val_loss: 0.9041 - val_accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.3968e-04 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.5943e-04 - accuracy: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.8669e-04 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.3185e-04 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 9.4814e-05 - accuracy: 1.0000 - val_loss: 0.9960 - val_accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.1250e-05 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 5.6692e-05 - accuracy: 1.0000 - val_loss: 1.0290 - val_accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.7838e-05 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.2427e-05 - accuracy: 1.0000 - val_loss: 1.0629 - val_accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.9030e-05 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 3.6731e-05 - accuracy: 1.0000 - val_loss: 1.0956 - val_accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.4926e-05 - accuracy: 1.0000 - val_loss: 1.1112 - val_accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.3291e-05 - accuracy: 1.0000 - val_loss: 1.1262 - val_accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 3.1592e-05 - accuracy: 1.0000 - val_loss: 1.1405 - val_accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.9728e-05 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.7723e-05 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 2.5590e-05 - accuracy: 1.0000 - val_loss: 1.1786 - val_accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.3428e-05 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.1329e-05 - accuracy: 1.0000 - val_loss: 1.1999 - val_accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.9354e-05 - accuracy: 1.0000 - val_loss: 1.2095 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7566e-05 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.5986e-05 - accuracy: 1.0000 - val_loss: 1.2264 - val_accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.4615e-05 - accuracy: 1.0000 - val_loss: 1.2339 - val_accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.3428e-05 - accuracy: 1.0000 - val_loss: 1.2409 - val_accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.2393e-05 - accuracy: 1.0000 - val_loss: 1.2473 - val_accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.1533e-05 - accuracy: 1.0000 - val_loss: 1.2533 - val_accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.0814e-05 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.0213e-05 - accuracy: 1.0000 - val_loss: 1.2641 - val_accuracy: 0.7500\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.7196e-06 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.7500\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 9.2896e-06 - accuracy: 1.0000 - val_loss: 1.2737 - val_accuracy: 0.7500\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 8.9533e-06 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.7500\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 8.6723e-06 - accuracy: 1.0000 - val_loss: 1.2820 - val_accuracy: 0.7500\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.4212e-06 - accuracy: 1.0000 - val_loss: 1.2857 - val_accuracy: 0.7500\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 8.2381e-06 - accuracy: 1.0000 - val_loss: 1.2892 - val_accuracy: 0.7500\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 8.0635e-06 - accuracy: 1.0000 - val_loss: 1.2924 - val_accuracy: 0.7500\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.9358e-06 - accuracy: 1.0000 - val_loss: 1.2954 - val_accuracy: 0.7500\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.8081e-06 - accuracy: 1.0000 - val_loss: 1.2982 - val_accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.7187e-06 - accuracy: 1.0000 - val_loss: 1.3008 - val_accuracy: 0.7500\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.6378e-06 - accuracy: 1.0000 - val_loss: 1.3032 - val_accuracy: 0.7500\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.5442e-06 - accuracy: 1.0000 - val_loss: 1.3054 - val_accuracy: 0.7500\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.4888e-06 - accuracy: 1.0000 - val_loss: 1.3075 - val_accuracy: 0.7500\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.4420e-06 - accuracy: 1.0000 - val_loss: 1.3095 - val_accuracy: 0.7500\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.3824e-06 - accuracy: 1.0000 - val_loss: 1.3113 - val_accuracy: 0.7500\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.3355e-06 - accuracy: 1.0000 - val_loss: 1.3130 - val_accuracy: 0.7500\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.2930e-06 - accuracy: 1.0000 - val_loss: 1.3146 - val_accuracy: 0.7500\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.2419e-06 - accuracy: 1.0000 - val_loss: 1.3160 - val_accuracy: 0.7500\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.2036e-06 - accuracy: 1.0000 - val_loss: 1.3174 - val_accuracy: 0.7500\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.1440e-06 - accuracy: 1.0000 - val_loss: 1.3187 - val_accuracy: 0.7500\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.1142e-06 - accuracy: 1.0000 - val_loss: 1.3199 - val_accuracy: 0.7500\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.0673e-06 - accuracy: 1.0000 - val_loss: 1.3211 - val_accuracy: 0.7500\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.0248e-06 - accuracy: 1.0000 - val_loss: 1.3221 - val_accuracy: 0.7500\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.9907e-06 - accuracy: 1.0000 - val_loss: 1.3231 - val_accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.9524e-06 - accuracy: 1.0000 - val_loss: 1.3241 - val_accuracy: 0.7500\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.8928e-06 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.7500\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.8545e-06 - accuracy: 1.0000 - val_loss: 1.3258 - val_accuracy: 0.7500\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.8161e-06 - accuracy: 1.0000 - val_loss: 1.3266 - val_accuracy: 0.7500\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.7821e-06 - accuracy: 1.0000 - val_loss: 1.3273 - val_accuracy: 0.7500\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.7395e-06 - accuracy: 1.0000 - val_loss: 1.3280 - val_accuracy: 0.7500\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.7182e-06 - accuracy: 1.0000 - val_loss: 1.3287 - val_accuracy: 0.7500\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.6842e-06 - accuracy: 1.0000 - val_loss: 1.3293 - val_accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.6373e-06 - accuracy: 1.0000 - val_loss: 1.3299 - val_accuracy: 0.6250\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.6160e-06 - accuracy: 1.0000 - val_loss: 1.3305 - val_accuracy: 0.6250\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.5777e-06 - accuracy: 1.0000 - val_loss: 1.3310 - val_accuracy: 0.6250\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.5394e-06 - accuracy: 1.0000 - val_loss: 1.3316 - val_accuracy: 0.6250\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.5139e-06 - accuracy: 1.0000 - val_loss: 1.3321 - val_accuracy: 0.6250\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.4968e-06 - accuracy: 1.0000 - val_loss: 1.3325 - val_accuracy: 0.6250\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.4628e-06 - accuracy: 1.0000 - val_loss: 1.3330 - val_accuracy: 0.6250\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.4415e-06 - accuracy: 1.0000 - val_loss: 1.3334 - val_accuracy: 0.6250\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.4032e-06 - accuracy: 1.0000 - val_loss: 1.3339 - val_accuracy: 0.6250\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.3904e-06 - accuracy: 1.0000 - val_loss: 1.3343 - val_accuracy: 0.6250\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.3734e-06 - accuracy: 1.0000 - val_loss: 1.3347 - val_accuracy: 0.6250\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.3436e-06 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.6250\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.3010e-06 - accuracy: 1.0000 - val_loss: 1.3355 - val_accuracy: 0.6250\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.2882e-06 - accuracy: 1.0000 - val_loss: 1.3359 - val_accuracy: 0.6250\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.2755e-06 - accuracy: 1.0000 - val_loss: 1.3363 - val_accuracy: 0.6250\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.2499e-06 - accuracy: 1.0000 - val_loss: 1.3366 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.2329e-06 - accuracy: 1.0000 - val_loss: 1.3370 - val_accuracy: 0.6250\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.2073e-06 - accuracy: 1.0000 - val_loss: 1.3374 - val_accuracy: 0.6250\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1946e-06 - accuracy: 1.0000 - val_loss: 1.3377 - val_accuracy: 0.6250\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1775e-06 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.6250\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1605e-06 - accuracy: 1.0000 - val_loss: 1.3384 - val_accuracy: 0.6250\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1392e-06 - accuracy: 1.0000 - val_loss: 1.3387 - val_accuracy: 0.6250\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1179e-06 - accuracy: 1.0000 - val_loss: 1.3390 - val_accuracy: 0.6250\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.1009e-06 - accuracy: 1.0000 - val_loss: 1.3393 - val_accuracy: 0.6250\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0839e-06 - accuracy: 1.0000 - val_loss: 1.3396 - val_accuracy: 0.6250\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0668e-06 - accuracy: 1.0000 - val_loss: 1.3399 - val_accuracy: 0.6250\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0498e-06 - accuracy: 1.0000 - val_loss: 1.3402 - val_accuracy: 0.6250\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0328e-06 - accuracy: 1.0000 - val_loss: 1.3405 - val_accuracy: 0.6250\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0200e-06 - accuracy: 1.0000 - val_loss: 1.3408 - val_accuracy: 0.6250\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.0030e-06 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.6250\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.9774e-06 - accuracy: 1.0000 - val_loss: 1.3414 - val_accuracy: 0.6250\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.9561e-06 - accuracy: 1.0000 - val_loss: 1.3417 - val_accuracy: 0.6250\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.9434e-06 - accuracy: 1.0000 - val_loss: 1.3420 - val_accuracy: 0.6250\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.9306e-06 - accuracy: 1.0000 - val_loss: 1.3422 - val_accuracy: 0.6250\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.9093e-06 - accuracy: 1.0000 - val_loss: 1.3425 - val_accuracy: 0.6250\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.9051e-06 - accuracy: 1.0000 - val_loss: 1.3428 - val_accuracy: 0.6250\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8753e-06 - accuracy: 1.0000 - val_loss: 1.3431 - val_accuracy: 0.6250\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.8540e-06 - accuracy: 1.0000 - val_loss: 1.3433 - val_accuracy: 0.6250\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8412e-06 - accuracy: 1.0000 - val_loss: 1.3436 - val_accuracy: 0.6250\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8199e-06 - accuracy: 1.0000 - val_loss: 1.3438 - val_accuracy: 0.6250\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8071e-06 - accuracy: 1.0000 - val_loss: 1.3441 - val_accuracy: 0.6250\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7901e-06 - accuracy: 1.0000 - val_loss: 1.3443 - val_accuracy: 0.6250\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7688e-06 - accuracy: 1.0000 - val_loss: 1.3446 - val_accuracy: 0.6250\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7561e-06 - accuracy: 1.0000 - val_loss: 1.3448 - val_accuracy: 0.6250\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7475e-06 - accuracy: 1.0000 - val_loss: 1.3450 - val_accuracy: 0.6250\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7305e-06 - accuracy: 1.0000 - val_loss: 1.3452 - val_accuracy: 0.6250\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7220e-06 - accuracy: 1.0000 - val_loss: 1.3454 - val_accuracy: 0.6250\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6964e-06 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.6250\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6879e-06 - accuracy: 1.0000 - val_loss: 1.3458 - val_accuracy: 0.6250\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6539e-06 - accuracy: 1.0000 - val_loss: 1.3460 - val_accuracy: 0.6250\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6411e-06 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.6250\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6368e-06 - accuracy: 1.0000 - val_loss: 1.3463 - val_accuracy: 0.6250\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6198e-06 - accuracy: 1.0000 - val_loss: 1.3465 - val_accuracy: 0.6250\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6028e-06 - accuracy: 1.0000 - val_loss: 1.3467 - val_accuracy: 0.6250\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5858e-06 - accuracy: 1.0000 - val_loss: 1.3468 - val_accuracy: 0.6250\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5687e-06 - accuracy: 1.0000 - val_loss: 1.3470 - val_accuracy: 0.6250\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5474e-06 - accuracy: 1.0000 - val_loss: 1.3472 - val_accuracy: 0.6250\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5304e-06 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.6250\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5176e-06 - accuracy: 1.0000 - val_loss: 1.3475 - val_accuracy: 0.6250\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5091e-06 - accuracy: 1.0000 - val_loss: 1.3477 - val_accuracy: 0.6250\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5006e-06 - accuracy: 1.0000 - val_loss: 1.3478 - val_accuracy: 0.6250\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4708e-06 - accuracy: 1.0000 - val_loss: 1.3480 - val_accuracy: 0.6250\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4538e-06 - accuracy: 1.0000 - val_loss: 1.3481 - val_accuracy: 0.6250\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4367e-06 - accuracy: 1.0000 - val_loss: 1.3483 - val_accuracy: 0.6250\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4240e-06 - accuracy: 1.0000 - val_loss: 1.3484 - val_accuracy: 0.6250\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.4112e-06 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.6250\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.3984e-06 - accuracy: 1.0000 - val_loss: 1.3487 - val_accuracy: 0.6250\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3857e-06 - accuracy: 1.0000 - val_loss: 1.3488 - val_accuracy: 0.6250\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3729e-06 - accuracy: 1.0000 - val_loss: 1.3489 - val_accuracy: 0.6250\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3559e-06 - accuracy: 1.0000 - val_loss: 1.3490 - val_accuracy: 0.6250\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.3303e-06 - accuracy: 1.0000 - val_loss: 1.3491 - val_accuracy: 0.6250\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.3175e-06 - accuracy: 1.0000 - val_loss: 1.3492 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.3048e-06 - accuracy: 1.0000 - val_loss: 1.3493 - val_accuracy: 0.6250\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.2877e-06 - accuracy: 1.0000 - val_loss: 1.3495 - val_accuracy: 0.6250\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.2792e-06 - accuracy: 1.0000 - val_loss: 1.3496 - val_accuracy: 0.6250\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2537e-06 - accuracy: 1.0000 - val_loss: 1.3498 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2494e-06 - accuracy: 1.0000 - val_loss: 1.3499 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.2324e-06 - accuracy: 1.0000 - val_loss: 1.3501 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2239e-06 - accuracy: 1.0000 - val_loss: 1.3502 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1898e-06 - accuracy: 1.0000 - val_loss: 1.3504 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1813e-06 - accuracy: 1.0000 - val_loss: 1.3505 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1600e-06 - accuracy: 1.0000 - val_loss: 1.3507 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1430e-06 - accuracy: 1.0000 - val_loss: 1.3508 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1217e-06 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1132e-06 - accuracy: 1.0000 - val_loss: 1.3511 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1004e-06 - accuracy: 1.0000 - val_loss: 1.3512 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0876e-06 - accuracy: 1.0000 - val_loss: 1.3514 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0791e-06 - accuracy: 1.0000 - val_loss: 1.3515 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0664e-06 - accuracy: 1.0000 - val_loss: 1.3517 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0451e-06 - accuracy: 1.0000 - val_loss: 1.3518 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0366e-06 - accuracy: 1.0000 - val_loss: 1.3520 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0195e-06 - accuracy: 1.0000 - val_loss: 1.3522 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0025e-06 - accuracy: 1.0000 - val_loss: 1.3523 - val_accuracy: 0.7500\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9940e-06 - accuracy: 1.0000 - val_loss: 1.3525 - val_accuracy: 0.7500\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9769e-06 - accuracy: 1.0000 - val_loss: 1.3527 - val_accuracy: 0.7500\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9599e-06 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.7500\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9429e-06 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9259e-06 - accuracy: 1.0000 - val_loss: 1.3532 - val_accuracy: 0.7500\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9259e-06 - accuracy: 1.0000 - val_loss: 1.3533 - val_accuracy: 0.7500\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9131e-06 - accuracy: 1.0000 - val_loss: 1.3535 - val_accuracy: 0.7500\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.8918e-06 - accuracy: 1.0000 - val_loss: 1.3537 - val_accuracy: 0.7500\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.8875e-06 - accuracy: 1.0000 - val_loss: 1.3538 - val_accuracy: 0.7500\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.8705e-06 - accuracy: 1.0000 - val_loss: 1.3540 - val_accuracy: 0.7500\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Test Loss: 1.3540006875991821\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# This is the basic LeNET model with ACTIVATION function as RELU and AveragePooling2D\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "model2.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model2.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "model2.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(120, activation='relu'))\n",
    "model2.add(Dense(84, activation='relu'))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Training\n",
    "num_epoch=200\n",
    "hist2 = model2.fit(x_train, y_train, batch_size=32, epochs= num_epoch, verbose=1, validation_data=(x_test, y_test))\n",
    "score2 = model2.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 25ms/step - loss: 1.0894 - accuracy: 0.4286 - val_loss: 1.0287 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.9972 - accuracy: 0.6429 - val_loss: 1.1544 - val_accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8241 - accuracy: 0.6071 - val_loss: 1.0473 - val_accuracy: 0.2500\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.8671 - accuracy: 0.6071 - val_loss: 0.9913 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.5781 - accuracy: 0.9286 - val_loss: 1.2370 - val_accuracy: 0.2500\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.5668 - accuracy: 0.7857 - val_loss: 0.8906 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.9643 - val_loss: 0.7978 - val_accuracy: 0.7500\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.8175 - val_accuracy: 0.6250\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.2257 - accuracy: 1.0000 - val_loss: 0.8966 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.1335 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 1.1344 - val_accuracy: 0.3750\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 1.0041 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.9491 - val_accuracy: 0.6250\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.1007 - val_accuracy: 0.6250\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.2382 - val_accuracy: 0.6250\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.6250\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6820 - val_accuracy: 0.3750\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.0844 - val_accuracy: 0.3750\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.5010 - val_accuracy: 0.3750\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.8769 - val_accuracy: 0.3750\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1625 - val_accuracy: 0.3750\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3380 - val_accuracy: 0.3750\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.8823e-04 - accuracy: 1.0000 - val_loss: 3.4215 - val_accuracy: 0.3750\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.8577e-04 - accuracy: 1.0000 - val_loss: 3.4433 - val_accuracy: 0.3750\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.7778e-04 - accuracy: 1.0000 - val_loss: 3.4223 - val_accuracy: 0.3750\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.5610e-04 - accuracy: 1.0000 - val_loss: 3.3632 - val_accuracy: 0.3750\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 9.0739e-05 - accuracy: 1.0000 - val_loss: 3.2894 - val_accuracy: 0.3750\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.6729e-05 - accuracy: 1.0000 - val_loss: 3.2226 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.9317e-05 - accuracy: 1.0000 - val_loss: 3.1668 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.1060e-05 - accuracy: 1.0000 - val_loss: 3.1239 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.8425e-05 - accuracy: 1.0000 - val_loss: 3.0902 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.9796e-05 - accuracy: 1.0000 - val_loss: 3.0632 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.4287e-05 - accuracy: 1.0000 - val_loss: 3.0427 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 4.1430e-05 - accuracy: 1.0000 - val_loss: 3.0284 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.0351e-05 - accuracy: 1.0000 - val_loss: 3.0249 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.9434e-05 - accuracy: 1.0000 - val_loss: 3.0324 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.6517e-05 - accuracy: 1.0000 - val_loss: 3.0503 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.9177e-05 - accuracy: 1.0000 - val_loss: 3.0775 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.6347e-05 - accuracy: 1.0000 - val_loss: 3.1129 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.8877e-05 - accuracy: 1.0000 - val_loss: 3.1562 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.8879e-05 - accuracy: 1.0000 - val_loss: 3.2057 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 3.8859e-05 - accuracy: 1.0000 - val_loss: 3.2600 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 3.0098e-05 - accuracy: 1.0000 - val_loss: 3.3175 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.3087e-05 - accuracy: 1.0000 - val_loss: 3.3765 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.7770e-05 - accuracy: 1.0000 - val_loss: 3.4352 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.3866e-05 - accuracy: 1.0000 - val_loss: 3.4928 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 1.1018e-05 - accuracy: 1.0000 - val_loss: 3.5482 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 8.9448e-06 - accuracy: 1.0000 - val_loss: 3.6009 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 7.4334e-06 - accuracy: 1.0000 - val_loss: 3.6506 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.3223e-06 - accuracy: 1.0000 - val_loss: 3.6952 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.4963e-06 - accuracy: 1.0000 - val_loss: 3.7362 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.8790e-06 - accuracy: 1.0000 - val_loss: 3.7742 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 4.4107e-06 - accuracy: 1.0000 - val_loss: 3.8093 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 4.0403e-06 - accuracy: 1.0000 - val_loss: 3.8414 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 3.7551e-06 - accuracy: 1.0000 - val_loss: 3.8708 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 3.5252e-06 - accuracy: 1.0000 - val_loss: 3.8977 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.3634e-06 - accuracy: 1.0000 - val_loss: 3.9223 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 3.1931e-06 - accuracy: 1.0000 - val_loss: 3.9446 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 3.0654e-06 - accuracy: 1.0000 - val_loss: 3.9648 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.9589e-06 - accuracy: 1.0000 - val_loss: 3.9831 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.8653e-06 - accuracy: 1.0000 - val_loss: 3.9998 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.7886e-06 - accuracy: 1.0000 - val_loss: 4.0148 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.7290e-06 - accuracy: 1.0000 - val_loss: 4.0282 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.6737e-06 - accuracy: 1.0000 - val_loss: 4.0402 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.6226e-06 - accuracy: 1.0000 - val_loss: 4.0508 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.5715e-06 - accuracy: 1.0000 - val_loss: 4.0602 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.5119e-06 - accuracy: 1.0000 - val_loss: 4.0684 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.4736e-06 - accuracy: 1.0000 - val_loss: 4.0756 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.4438e-06 - accuracy: 1.0000 - val_loss: 4.0818 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.4055e-06 - accuracy: 1.0000 - val_loss: 4.0871 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 2.3629e-06 - accuracy: 1.0000 - val_loss: 4.0916 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.3331e-06 - accuracy: 1.0000 - val_loss: 4.0954 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 2.3033e-06 - accuracy: 1.0000 - val_loss: 4.0985 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.2735e-06 - accuracy: 1.0000 - val_loss: 4.1010 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.2479e-06 - accuracy: 1.0000 - val_loss: 4.1029 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 2.2139e-06 - accuracy: 1.0000 - val_loss: 4.1044 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 2.1841e-06 - accuracy: 1.0000 - val_loss: 4.1053 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.1500e-06 - accuracy: 1.0000 - val_loss: 4.1059 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 2.1287e-06 - accuracy: 1.0000 - val_loss: 4.1062 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 2.1032e-06 - accuracy: 1.0000 - val_loss: 4.1061 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 2.0947e-06 - accuracy: 1.0000 - val_loss: 4.1057 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 2.0691e-06 - accuracy: 1.0000 - val_loss: 4.1051 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 2.0478e-06 - accuracy: 1.0000 - val_loss: 4.1042 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 2.0265e-06 - accuracy: 1.0000 - val_loss: 4.1032 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 2.0053e-06 - accuracy: 1.0000 - val_loss: 4.1019 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.9840e-06 - accuracy: 1.0000 - val_loss: 4.1005 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.9712e-06 - accuracy: 1.0000 - val_loss: 4.0990 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.9542e-06 - accuracy: 1.0000 - val_loss: 4.0974 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.9329e-06 - accuracy: 1.0000 - val_loss: 4.0957 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.9159e-06 - accuracy: 1.0000 - val_loss: 4.0939 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 1.9116e-06 - accuracy: 1.0000 - val_loss: 4.0920 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.9031e-06 - accuracy: 1.0000 - val_loss: 4.0901 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 1.8733e-06 - accuracy: 1.0000 - val_loss: 4.0881 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.8520e-06 - accuracy: 1.0000 - val_loss: 4.0861 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.8435e-06 - accuracy: 1.0000 - val_loss: 4.0841 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 1.8350e-06 - accuracy: 1.0000 - val_loss: 4.0821 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.8307e-06 - accuracy: 1.0000 - val_loss: 4.0801 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.8094e-06 - accuracy: 1.0000 - val_loss: 4.0781 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.8052e-06 - accuracy: 1.0000 - val_loss: 4.0761 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.7924e-06 - accuracy: 1.0000 - val_loss: 4.0741 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.7881e-06 - accuracy: 1.0000 - val_loss: 4.0722 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.7754e-06 - accuracy: 1.0000 - val_loss: 4.0702 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.7626e-06 - accuracy: 1.0000 - val_loss: 4.0683 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.7498e-06 - accuracy: 1.0000 - val_loss: 4.0664 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7456e-06 - accuracy: 1.0000 - val_loss: 4.0646 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7328e-06 - accuracy: 1.0000 - val_loss: 4.0628 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7285e-06 - accuracy: 1.0000 - val_loss: 4.0610 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7243e-06 - accuracy: 1.0000 - val_loss: 4.0592 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.7115e-06 - accuracy: 1.0000 - val_loss: 4.0575 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.7030e-06 - accuracy: 1.0000 - val_loss: 4.0559 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6987e-06 - accuracy: 1.0000 - val_loss: 4.0542 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6945e-06 - accuracy: 1.0000 - val_loss: 4.0527 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6902e-06 - accuracy: 1.0000 - val_loss: 4.0511 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6860e-06 - accuracy: 1.0000 - val_loss: 4.0496 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6860e-06 - accuracy: 1.0000 - val_loss: 4.0482 - val_accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6774e-06 - accuracy: 1.0000 - val_loss: 4.0467 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.6774e-06 - accuracy: 1.0000 - val_loss: 4.0454 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6689e-06 - accuracy: 1.0000 - val_loss: 4.0441 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6689e-06 - accuracy: 1.0000 - val_loss: 4.0428 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.6604e-06 - accuracy: 1.0000 - val_loss: 4.0416 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6604e-06 - accuracy: 1.0000 - val_loss: 4.0404 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6604e-06 - accuracy: 1.0000 - val_loss: 4.0392 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.6434e-06 - accuracy: 1.0000 - val_loss: 4.0381 - val_accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6391e-06 - accuracy: 1.0000 - val_loss: 4.0370 - val_accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6306e-06 - accuracy: 1.0000 - val_loss: 4.0360 - val_accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6306e-06 - accuracy: 1.0000 - val_loss: 4.0350 - val_accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6306e-06 - accuracy: 1.0000 - val_loss: 4.0341 - val_accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6221e-06 - accuracy: 1.0000 - val_loss: 4.0332 - val_accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6178e-06 - accuracy: 1.0000 - val_loss: 4.0323 - val_accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6093e-06 - accuracy: 1.0000 - val_loss: 4.0314 - val_accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.6008e-06 - accuracy: 1.0000 - val_loss: 4.0306 - val_accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5965e-06 - accuracy: 1.0000 - val_loss: 4.0298 - val_accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.5923e-06 - accuracy: 1.0000 - val_loss: 4.0291 - val_accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.5923e-06 - accuracy: 1.0000 - val_loss: 4.0283 - val_accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 1.5880e-06 - accuracy: 1.0000 - val_loss: 4.0276 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.5838e-06 - accuracy: 1.0000 - val_loss: 4.0269 - val_accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.5753e-06 - accuracy: 1.0000 - val_loss: 4.0263 - val_accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.5710e-06 - accuracy: 1.0000 - val_loss: 4.0257 - val_accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.5667e-06 - accuracy: 1.0000 - val_loss: 4.0250 - val_accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.5667e-06 - accuracy: 1.0000 - val_loss: 4.0245 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5625e-06 - accuracy: 1.0000 - val_loss: 4.0239 - val_accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5582e-06 - accuracy: 1.0000 - val_loss: 4.0233 - val_accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5582e-06 - accuracy: 1.0000 - val_loss: 4.0228 - val_accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5540e-06 - accuracy: 1.0000 - val_loss: 4.0223 - val_accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5455e-06 - accuracy: 1.0000 - val_loss: 4.0218 - val_accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5369e-06 - accuracy: 1.0000 - val_loss: 4.0213 - val_accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5369e-06 - accuracy: 1.0000 - val_loss: 4.0209 - val_accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5327e-06 - accuracy: 1.0000 - val_loss: 4.0205 - val_accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5327e-06 - accuracy: 1.0000 - val_loss: 4.0200 - val_accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5284e-06 - accuracy: 1.0000 - val_loss: 4.0196 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5284e-06 - accuracy: 1.0000 - val_loss: 4.0192 - val_accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5242e-06 - accuracy: 1.0000 - val_loss: 4.0189 - val_accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.5242e-06 - accuracy: 1.0000 - val_loss: 4.0185 - val_accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.5199e-06 - accuracy: 1.0000 - val_loss: 4.0182 - val_accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.5199e-06 - accuracy: 1.0000 - val_loss: 4.0179 - val_accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5114e-06 - accuracy: 1.0000 - val_loss: 4.0175 - val_accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5071e-06 - accuracy: 1.0000 - val_loss: 4.0172 - val_accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5029e-06 - accuracy: 1.0000 - val_loss: 4.0170 - val_accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5029e-06 - accuracy: 1.0000 - val_loss: 4.0167 - val_accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.5029e-06 - accuracy: 1.0000 - val_loss: 4.0164 - val_accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4944e-06 - accuracy: 1.0000 - val_loss: 4.0162 - val_accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4944e-06 - accuracy: 1.0000 - val_loss: 4.0159 - val_accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4901e-06 - accuracy: 1.0000 - val_loss: 4.0157 - val_accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4901e-06 - accuracy: 1.0000 - val_loss: 4.0155 - val_accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4901e-06 - accuracy: 1.0000 - val_loss: 4.0152 - val_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4859e-06 - accuracy: 1.0000 - val_loss: 4.0150 - val_accuracy: 0.5000\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 1.4859e-06 - accuracy: 1.0000 - val_loss: 4.0148 - val_accuracy: 0.5000\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 1.4859e-06 - accuracy: 1.0000 - val_loss: 4.0146 - val_accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.4731e-06 - accuracy: 1.0000 - val_loss: 4.0145 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.4731e-06 - accuracy: 1.0000 - val_loss: 4.0143 - val_accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4688e-06 - accuracy: 1.0000 - val_loss: 4.0141 - val_accuracy: 0.5000\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.4646e-06 - accuracy: 1.0000 - val_loss: 4.0140 - val_accuracy: 0.5000\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4646e-06 - accuracy: 1.0000 - val_loss: 4.0137 - val_accuracy: 0.5000\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 1.4646e-06 - accuracy: 1.0000 - val_loss: 4.0133 - val_accuracy: 0.5000\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.4603e-06 - accuracy: 1.0000 - val_loss: 4.0131 - val_accuracy: 0.5000\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4603e-06 - accuracy: 1.0000 - val_loss: 4.0131 - val_accuracy: 0.5000\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4561e-06 - accuracy: 1.0000 - val_loss: 4.0130 - val_accuracy: 0.5000\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.4518e-06 - accuracy: 1.0000 - val_loss: 4.0128 - val_accuracy: 0.5000\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4475e-06 - accuracy: 1.0000 - val_loss: 4.0125 - val_accuracy: 0.5000\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4475e-06 - accuracy: 1.0000 - val_loss: 4.0123 - val_accuracy: 0.5000\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4433e-06 - accuracy: 1.0000 - val_loss: 4.0122 - val_accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4433e-06 - accuracy: 1.0000 - val_loss: 4.0123 - val_accuracy: 0.5000\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 1.4433e-06 - accuracy: 1.0000 - val_loss: 4.0122 - val_accuracy: 0.5000\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4348e-06 - accuracy: 1.0000 - val_loss: 4.0120 - val_accuracy: 0.5000\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.4263e-06 - accuracy: 1.0000 - val_loss: 4.0118 - val_accuracy: 0.5000\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4263e-06 - accuracy: 1.0000 - val_loss: 4.0115 - val_accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 1.4263e-06 - accuracy: 1.0000 - val_loss: 4.0112 - val_accuracy: 0.5000\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4220e-06 - accuracy: 1.0000 - val_loss: 4.0114 - val_accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4220e-06 - accuracy: 1.0000 - val_loss: 4.0115 - val_accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4220e-06 - accuracy: 1.0000 - val_loss: 4.0115 - val_accuracy: 0.5000\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4177e-06 - accuracy: 1.0000 - val_loss: 4.0114 - val_accuracy: 0.5000\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4050e-06 - accuracy: 1.0000 - val_loss: 4.0112 - val_accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4050e-06 - accuracy: 1.0000 - val_loss: 4.0110 - val_accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4050e-06 - accuracy: 1.0000 - val_loss: 4.0107 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.4007e-06 - accuracy: 1.0000 - val_loss: 4.0103 - val_accuracy: 0.5000\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 1.3964e-06 - accuracy: 1.0000 - val_loss: 4.0099 - val_accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3922e-06 - accuracy: 1.0000 - val_loss: 4.0098 - val_accuracy: 0.5000\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3922e-06 - accuracy: 1.0000 - val_loss: 4.0099 - val_accuracy: 0.5000\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3922e-06 - accuracy: 1.0000 - val_loss: 4.0099 - val_accuracy: 0.5000\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 1.3837e-06 - accuracy: 1.0000 - val_loss: 4.0099 - val_accuracy: 0.5000\n",
      "8/8 [==============================] - 0s 5ms/step\n",
      "Test Loss: 4.009856224060059\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# This is the basic LeNET model with ACTIVATION function as RELU and POOLING as MAXPOOLING2D\n",
    "model3 = Sequential()\n",
    "model3.add(Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "model3.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(120, activation='relu'))\n",
    "model3.add(Dense(84, activation='relu'))\n",
    "model3.add(Dense(3, activation='softmax'))\n",
    "model3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Training\n",
    "num_epoch=200\n",
    "hist3 = model3.fit(x_train, y_train, batch_size=32, epochs= num_epoch, verbose=1, validation_data=(x_test, y_test))\n",
    "score3 = model3.evaluate(x_test, y_test)\n",
    "print('Test Loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 560x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Print the observations of Accuracy among different models\n",
    "xc=range(50)\n",
    "acc0=hist.history['accuracy']\n",
    "acc1=hist1.history['accuracy']\n",
    "acc2=hist2.history['accuracy']\n",
    "acc3=hist3.history['accuracy']\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,acc0[0:50])\n",
    "plt.plot(xc,acc1[0:50])\n",
    "plt.plot(xc,acc2[0:50])\n",
    "plt.plot(xc,acc3[0:50])\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy in different models')\n",
    "plt.grid(True)\n",
    "plt.legend(['tanh+AV Pool','tanh+Max Pool','ReLU+AV Pool','ReLU+Max Pool'],loc=4)\n",
    "plt.style.use(['classic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Number of images taken for the training is very low (28 images). Increasing the dataset might show a different trend.\n",
    "\n",
    "**Role of ACTIVATION FUNCTIONS in Model Training:**\n",
    "Here, we observe that the Relu function has achieved maximum accuracy in very less number of epochs. \n",
    "Indeed, Relu function helps the model to learn faster, however the accuracy drops is the lowest.\n",
    "\n",
    "**Role of POOLING in Model Training:**\n",
    "Also, we can observe that MaxPooling has a considerable impact on the Model Training. Looks like MaxPooling complements the features of Activation Functions. It actually helps to learn faster irrespective of the models. Though tanh function promotes gradual learning, MaxPooling has given it a good push for faster learning! \n",
    "\n",
    "**Role of EPOCHS in Model Training:**\n",
    "The range of Epochs given for model training was from 0-200. Interestingly, all the models have learnt in less than 40 epochs.\n",
    "Number of epochs definetly plays a role, however, after some optimum number of epochs (here it is around 35), we can surely stop the training thereby optimizing the available resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
